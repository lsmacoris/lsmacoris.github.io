{
  "hash": "5a45ada9a6e2bbcee7a1dbfbda35549a",
  "result": {
    "markdown": "---\ntitle: \"How to Download and Efficiently Manage Stock Data from Yahoo! Finance for Multiple Tickers using R\"\ndescription: \"ETL routines using functional programming for working with large sets of stock-level data simultaneously.\"\nauthor:\n  - name: Lucas S. Macoris\n    url: https://lsmacoris.github.io/\n    orcid: 0000-0003-0732-5011\n    affiliation: Ph.D. in Economics @ INSPER (Sao Paulo, Brazil) | Data Science @ Circana\n    affiliation-url: https://www.circana.com/\ndate: 9-27-2023\ncategories: [Yahoo! Finance, Stocks,R] # self-defined categories\ncitation: \n  url: https://lsmacoris.github.io/posts/Efficiently-Download-and-Manage-Yahoo-Finance-Data-With-R\nimage: post_thumbnail.jpg\ndraft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\n---\n\n\n## Downloading Multiple Stock-level Information from Yahoo! Finance using R\n\nWhenever downloading data from *Yahoo! Finance* using `quantmod`, I've always found it difficult to organize a collection of objects in cases where the number of requested tickers large. Not only for the sake of organization, sometimes we want to perform calculations that span a large set of assets and visualize results in an aggregate fashion. For example, say that one wants estimate how persistent prices for several stocks are using past information. The naivest way to do it would be to loop over several tickers, collect the metric, and append to a `data.frame()` that will be used to analyze metrics (*i.e*, using histograms and summary statistics).\n\nAlthough this is totally up to you, I've selected a few packages that make the overall explanation easier:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npackages.to.load=c(\"ggplot2\",\"dplyr\",\"PerformanceAnalytics\",\"quantmod\",\"xts\",\"purrr\",\"glue\")\n\n#Load all packages\nsapply(packages.to.load,library,character.only = TRUE)\n```\n:::\n\n\nUsing  the `getSymbols()` function from `quantmod`, we can loop over a list of stocks and collect the information:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist_of_assets=c('AAPL','MSFT','GOOG','GOOGL','AMZN','NVDA','TSLA')\n\nfor (assets in list_of_assets){\n  getSymbols(assets)\n}\n```\n:::\n\n\n...which, by default, will load each individual `asset` in the `list_of_assets` that was passed to `GetSymbols()` in your `R` session:\n\n![Figure 1: R-Session-Overloaded](r-session-example.jpg)\n\n## Handling Multiple Tickers from Yahoo! Finance\n\nIn this very simple example, having a list of seven distinct does not create a messy `R` environment to work, but that can easily be the case in applications where you need to constantly track a higher number of stocks. Likewise, since you've downloaded data for multiple tickers, it is likely the case that you need to perform operations for each asset. In this case, since each assets is loaded as a `.xts` object in your session, you might need to `loop` over each asset in order to perform a given operation.\n\nSay, for example, that after loading the data, we wanted to calculate a 30-day moving average and store the results. Since each `asset` has been loaded separately in our session, we need to iterate over each asset, collect the column that we want to calculate a moving-average, and collapse the results:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Initialize an empty xts to collect information\nSMA_df=xts()\n\nfor(asset in list_of_assets){\n  \n  #Collect the Close column and perform a moving average\n  SMA_df=SMA_df%>%merge.xts(get(asset)[,glue('{asset}.Close')]%>%SMA(30)%>%setNames(glue('{asset}_SMA')))\n  \n}\n\n#Plot xts\nplot.xts(SMA_df,main='30-day moving average\\nfor selected U.S. stocks')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\naddLegend(\"topleft\",legend.names = list_of_assets,col=1:length(list_of_assets),lty=1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n:::\n\n\nWell, that seemed to do the trick. However, is this something that we might want to adopt for all cases with multiple tickers? Probably not. If the number of tickers is large (e.g, $>>100$) and the calculations that we need to perform are more computational-intensive, such as extracting a time-series component from our data, iterating over assets using `for` loops will be an inneficient way of handling these tasks, as each computation will require you to loop over different `.xts` objects stored in your session.\n\n## Applying Functional Programming to Stock-Level Information\n\nI happened to find `purrr` (see [documentation](https://purrr.tidyverse.org)) to be a handy companion for tasks like this. When using its functional programming features, not only we can have an easier way to work with multiple tickers, but also work with a much cleaner environment -- as no one  wants to have 100+ `xts` objects in our environment everytime when running the code.\n\nThis notebook showcases how to collect and organize data from *Yahoo! Finance* and perform calculations that span across all tickers. This can be very useful, for example, when creating an automated screening system in which, based on a set of technical indicators, can easily run a screening process in order to select a bundle of assets for a given trading strategy.\n\nI am  going to present a simple example using a set of brazilian traded stocks traded in *Bovespa*. All the stocks are presented in the auxiliary *.csv* file, `Assets.csv`, and can be changed to accomodate any stock available in *Yahoo! Finance* servers. This file contains approximataely 75 unique tickers from the Brazilian Stock Market that were tradable back in 2019. What makes it difficult to use `quantmod`'s capabilities is the fact that some tickers are not available and/or do not have data for the requested period. Whenever running a `for` loop and iterate through these tickers, one might come across a `warning` or an `error` message that crashes the task. To overcome such difficulty, I have developed some wrappers using the `tryCatch()` approach.\n\n**Important Remark**: *Yahoo! Finance* generally offers data with splits and dividends adjustments and therefore may not be the same as the brokerage information. In this sense, recommendations must also be analyzed through technical indicators presented on the brokerage account. Additionally, one can change the log in order to use any other provider of financial data of the same format, such as [*AlphaVantage*](https://www.alphavantage.co/), which also has an API support into the `quantmod` library.\n\n## Using Functional Programming with Yahoo! Finance in R\n\nAfter loading the data, we can iterate through our list of tickers to organize the information. One important callout is that whenever we want to retrieve some technical indicators (for example, from the `TTR` package), we need to ensure that there are no `NA`s in our data. For that, we'll wrap our call using the `na.locf()` call to repeat the latest information available:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Load the list of Assets\nAssets<-read.csv('Assets.csv',sep=';',encoding = 'UTF-8',header = TRUE,stringsAsFactors = FALSE)[,1]\n\n#Let's take a look at the structure of the file\nAssets%>%head(5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ABEV3.SA\" \"AZUL4.SA\" \"B3SA3.SA\" \"BBAS3.SA\" \"BBDC3.SA\"\n```\n:::\n\n```{.r .cell-code}\n#create empty data.frames to collect downloaded and error cases\ndownloaded=data.frame()\nerrors=data.frame()\n\n#Getting Data: now, we are going to request for chunks of 5 assets per time in Yahoo Finance server.\n\nadjust_ticker_data <- function(ticker){\n  \n  return(na.locf(Cl(ticker)))\n  \n}\n\nTickers=list()\n\nfor (i in Assets){\n\n  Data=suppressWarnings(\n      tryCatch({\n      \n      adjust_ticker_data(getSymbols(i,\n                                    auto.assign = FALSE,\n                                    from='2019-01-01',to=Sys.Date())\n                         )},\n      error = function(e){\n      assign(\"errors\",rbind(errors,i),envir=.GlobalEnv)\n      }\n    )\n  )\n  \n#If successful, we'll be able to have a xts object to get information on prices:\n  \n  if(is.xts(Data)){\n  downloaded=downloaded%>%rbind(i)\n  Bands = do.call(merge,lapply(Data,BBands))\n  RSI = do.call(merge,lapply(Data,RSI))\n  SMA= do.call(merge,lapply(Data,SMA))\n  \n  Tickers[[i]]=list(Data=Data,\n                    BBands=Bands,\n                    RSI=RSI,\n                    SMA=SMA)\n  \n  #Clear from memory to avoid if conditions to be satisfied with past iterations\n  rm(Data,Bands,RSI,SMA)\n  }\n\n}\n\n  #Retrieve status information:\n  message(glue('Data not downloaded for the following tickers: {errors}.'))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nData not downloaded for the following tickers: c(\"BRML3.SA\", \"BTOW3.SA\", \"IGTA3.SA\", \"LAME4.SA\", \"SMLS3.SA\", \"TIMP3.SA\", \"VIVT4.SA\", \"VVAR3.SA\", \"PARD3.SA\", \"HGTX3.SA\", \"GNDI3.SA\", \"SULA11.SA\").\n```\n:::\n\n```{.r .cell-code}\n  message(glue('Successfully downloaded data for the following tickers: {downloaded}.'))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSuccessfully downloaded data for the following tickers: c(\"ABEV3.SA\", \"AZUL4.SA\", \"B3SA3.SA\", \"BBAS3.SA\", \"BBDC3.SA\", \"BBDC4.SA\", \"BBSE3.SA\", \"BRAP4.SA\", \"BRFS3.SA\", \"BRKM5.SA\", \"CCRO3.SA\", \"CIEL3.SA\", \"CMIG4.SA\", \"CSAN3.SA\", \"CSNA3.SA\", \"CVCB3.SA\", \"CYRE3.SA\", \"ECOR3.SA\", \"EGIE3.SA\", \"ELET3.SA\", \"ELET6.SA\", \"EMBR3.SA\", \"ENBR3.SA\", \"EQTL3.SA\", \"FLRY3.SA\", \"GGBR4.SA\", \"GOAU4.SA\", \"GOLL4.SA\", \"HYPE3.SA\", \"IRBR3.SA\", \"ITSA4.SA\", \"ITUB4.SA\", \"JBSS3.SA\", \"KLBN11.SA\", \"COGN3.SA\", \"LREN3.SA\", \"MGLU3.SA\", \"MRFG3.SA\", \"MRVE3.SA\", \"MULT3.SA\", \"PETR3.SA\", \"PETR4.SA\", \n\"QUAL3.SA\", \"RADL3.SA\", \"RAIL3.SA\", \"RENT3.SA\", \"SANB11.SA\", \"SBSP3.SA\", \"SUZB3.SA\", \"UGPA3.SA\", \"USIM5.SA\", \"VALE3.SA\", \"WEGE3.SA\", \"YDUQ3.SA\", \"ODPV3.SA\", \"GRND3.SA\", \"ARZZ3.SA\", \"HAPV3.SA\", \"CRFB3.SA\", \"TOTS3.SA\", \"PSSA3.SA\", \"UGPA3.SA\", \"EZTC3.SA\", \"GFSA3.SA\").\n```\n:::\n:::\n\n\nWhat is very interesting when collecting information using lists is that we can easily organize data in a streamlined fashion that is very flexible when working with different data structure dimensions. For example, when inspecting the newly created `Tickers` list, it contains:\n\n1. A first layer of 64 named lists, one for each ticker that has been successfully downloaded;\n2. One additional layer for the adjusted closing data; and\n3. Additional layers for each technical indicator\n\nDue to the way that it was structured, these objects do not need to hold a specific row $\\times$ column dimension, as every object is stored in a single nested list, making our life much easier when dealing with multiple tickers:\n\n![Figure 2: R Session when using list-like methods.](r-session-purrr.jpg)\n\n![Figure 3: Structure of a list with multiple tickers](r-list-structure.jpg)\n\n## Retrieve List Information with Functional Programming using purrr\n\nUsing `purrr` capabilities for functional programming can make overwhelming tasks that involve multiple tickers much easier. More specifically, `map` and its companions allow us to map functions across different lists, collect objects, and pipe it for other analysis and/or visualizations. Say, for example, that we want to understand what is the distribution of price persistence across *all* tickers. We can run an $ARIMA(p,d,q)$ model for each ticker, collec the coefficients, and then plot an histogram to understand the distribution of the autoregressive component, $p$.\n\nIn order to do that, we will create a new list that will extract all `Data` components of the nested ticker lists. With that, we will use a combination of the `map_*` family functions from `purrr` to feed the results directly into a `ggplot` chart -- everything without creating a single new object!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Using map_* + ggplot to analyze the distribution of the autoregressive parameter \n\nsuppressWarnings(lapply(Tickers,'[[',\"Data\")%>%\n  map(arima,order=c(1,1,1)))%>%\n  map(\"coef\")%>%\n  map_df('ar1')%>%t()%>%as.data.frame()%>%\n  ggplot(aes(x=V1))+\n  geom_histogram(binwidth = 0.1)+\n  theme_minimal()+\n  labs(x='Autoregressive Parameter',\n       y='Count',\n       title='Distribution of autoregressive parameters across Brazilian stocks',\n       subtitle='Assuming an ARIMA(1,1,1) model for the stocks')+\n  scale_y_continuous(breaks=seq(1,10,1))+\n  scale_x_continuous(breaks=seq(-1,1,0.15))+\n  geom_density(aes(y=0.075*..count..),size=1,col='red',linetype='dashed')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n## Final Thoughts: Financial Data with Functional Programming in R \n\nThis example outlines just a simple application of functional programming for a situation where there are several nested lists holding diverse structures. However, applications go far beyond than that, and it is something that I would definitely recommend to anyone that is working with stock price data that spans multiple tickers.\n\nI definitely recommend going through the documentation of the packages used herein, as well as investigating some other very interesting variations of *Yahoo! Finance* data collection in R. In special, the `yfR` (see documentation [here](https://github.com/ropensci/yfR)) package uses parallel computing to speed up the processing time when downloading multiple tickers.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}