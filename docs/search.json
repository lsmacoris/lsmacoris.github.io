[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lucas S. Macoris",
    "section": "",
    "text": "Welcome to my personal website üòâ\n\nI am an Applied Economist currently serving as a Media Marketing Mix & Data Science Consultant at Circana. I have received my Ph.D.¬†in Economics from INSPER (Institute of Education and Research, Sao Paulo) in May, 2023.\nStarting February 2024, I will be joining Getulio Vargas Foundation (FGV - EAESP) as an Assistant Professor (part-time) of Finance in the Accounting, Finance and Control Department.\nOn this site, you will find a repository of valuable resources including lecture notes, technical handouts, and blog posts. These materials delve into my academic and practitioner interests, spanning Corporate Finance, Causal Identification, R/Python Programming, and Consumer Behavior and Analytics. For comprehensive access, please visit my GitHub page, which also hosts supplementary materials like coding notebooks and sample datasets.\nBy sharing some of my ideas along with a few lines of code, I aim to bridge the gap between what I am passionate about and what the broader community can learn from it. Hopefully, in the very long end, I can make someone passionate about these things, too ‚ù§Ô∏è\nIf you have any questions and/or comments, do not hesitate to reach out to through this email."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "Lucas Macoris. Photo: Juliana Rizieri.\n\n\n\n\n\n\n\n\nI have received my Ph.D.¬†in Economics from INSPER (Institute of Education and Research, Sao Paulo, Brazil) in May, 2023. I have also received my Bachelor‚Äôs (in Management) and Master‚Äôs Degree (Finance, Economics, and Econometrics) from the University of Sao Paulo (USP, Sao Paulo, Brazil).\nMy academic research lies at the intersection between Corporate Finance and Financial Intermediation. More specifically, I study how market frictions affect firms‚Äô financing and investment decisions, and what are the implications of these imperfections in terms of managerial action, firms‚Äô future outcomes, and market responses.\nThroughout my academic journey, data in its diverse formats has been an integral part of my daily activities ‚Äî a constant that will persist. I started coding when I first discovered DataCamp and enrolled in my first R programming course. Initially daunted by the complexity and the sheer shift from user-interface schemes, such as Excel, to programming languages, I found solace in the vibrant and supportive community spread in innumerous discussion threads in R forums, StackOverFlow pages, lecture notes, among other publicly shared materials. The ability to navigate common questions, learning from the shared knowledge, transformed this significant transition into an enjoyable experience that I aim to contribute to.\nAcquiring such skills provided me flexibility and allowed me to explore creativity to better express ideas and look for answering interesting questions without the hasle of putting hours of work in repetitive tasks. I used R, Python, SQL, LaTeX, and all of its related interfaces in literally everything related to my research agenda, as well as during several undergraduate/graduate courses on applied economics and finance, where I worked as a Teaching Assistant during my Ph.D.¬†enrollment, as well as during my experience working as a Research Assistant in the Brazilian Central Bank.\nAll in all, from what I can say, there‚Äôs really nothing that could make me happier in my profession ‚Äì I hope this page explains you why."
  },
  {
    "objectID": "practice.html",
    "href": "practice.html",
    "title": "What I have been reading recently‚Ä¶",
    "section": "",
    "text": "In case you wonder what are good reading tips, here‚Äôs a few list of very interesting, technical papers that I have been reading extensively and I recommend to everyone that is interested in applied economics (and, in some cases, quantitative marketing):"
  },
  {
    "objectID": "academic.html",
    "href": "academic.html",
    "title": "My Academic Research",
    "section": "",
    "text": "My research lies at the intersection between Corporate Finance and Financial Intermediation. More specifically, I study how market frictions affect firms‚Äô financing and investment decisions, and what are the implications of these imperfections in terms of managerial action, firms‚Äô future outcomes, and market responses.\nBelow you can find some of my published/work-in-progress academic work:\n\n\nM&A under financing frictions: evidence from credit supply shortfalls\nJoint work with Luis Ricardo Kabbach de Castro (University of Navarra)\n\nStatus: Working Paper. Draft verison can be obtained here.\nPresentations: 2022 European Financial Management Association (EFMA), 2022 Academy of Management (AOM), Insper, Getulio Vargas Foundation (EAESP), University of Navarra, Brazilian Finance Meeting.\n\nAbstract: despite empirical evidence showing that firms‚Äô investments decrease during periods of credit supply shortfalls, little is known about how firms can eventually circumvent the adverse effects of negative credit supply shocks. In this paper, we show that firms can relieve financing frictions during banking crisis periods by selling equity stakes to outside investors, and the specific channel that relieves such frictions is a shift from domestic to cross-border issuance in countries with historically higher issuance volume. To do so, we examine Mergers and Acquisitions (M&A) transactions worldwide between 1990-2019 and the outcomes of targeted firms the deal by exploring cross-sectional variation in the supply of credit induced by banking crises. The results show that firms that have higher levels of expiring debt maturities in the year of the credit shock are more likely to become targets in M&A deals. Moreover, we find strong evidence that target firms invest more and issue more debt after the deal relative to their counterparts. Finally, we show that these firms are shifting from issuing debt in their own countries to issuing debt in countries with historically higher issuance volume. All in all, these results show that M&As can work as leeway to relieve financing frictions in periods when credit supply frictions are more prevalent.\n\n\n\nMinority Acquisitons and Financial Constraints: reaping big benefits from small shareholders\nJoint work with Luis Ricardo Kabbach de Castro (University of Navarra), Dirk Boehe (Un. of Massey) and Aquiles Kalatzis (University of Sao Paulo)\n\nStatus: Published at the Corporate Governance: an International Review - Click here to access\nPresentations: presented at the XVIII Brazilian Finance (2018) Meeting, accepted at AIB Conference (2018).\n\nAbstract: using a panel of approximately 12,000 domestic and cross-border deals, our results show a positive and statistically significant relationship between the target firms‚Äô financial constraints and the occurrence of minority acquisitions. Moreover, compared to a matched sample, there is a statistically significant difference between the growth in investment and leverage of target firms after deal completion, indicating the effectiveness of minority acquisitions in alleviating target‚Äôs financial constraints. At the institutional level, we find that the level of financial development and legal protection in a country are also positively related to minority acquisitions.\n\n\n\nHow has COVID-19 affected air quality in Sao Paulo?\nJoint work with Andre Mancha (Insper) and Naercio Aquino Menezes-Filho (Insper)\n\nStatus: Revise and Resubmit (R&R). Draft version can be obtained here.\n\nAbstract: we assess how social distancing norms following the COVID-19 outbreak affected pollutant levels in Sao Paulo, one of the largest metropolitan areas in the world. We estimate a difference-in-differences model, exploiting exogenous variation in lockdown rules across municipalities to evaluate different mechanisms that have driven air quality improvement in the city. Using hourly air pollution levels measured in thirty-three monitoring stations in the state of Sao Paulo, we find an average decrease of 24.4% in air pollution after the first days of the capital‚Äôs quarantine announcement, with heterogeneous effects across types of pollutants. We also compare this effect with exogenous cancellations of traffic restriction rules that occurred between 2000-2018. Our results shed light on the discussion of public policies focused on air quality improvement in large metropolitan areas, which can be a helpful guidance for policymakers in the post-pandemic period.\n\n\n\nCross-border and domestic minority acquisitions and financial constraints: Reaping big benefits from small shareholders?\nJoint work with Luiz Ricardo Kabbach de Castro (UNAV-ES), Aquiles Kalatzis (USP), and Dirk. Boehe (Africa Business School)\n\nStatus: Published at the Corporate Governance: an International Review (2022). Click here to access.\n\nAbstract: using a sample of 11,926 domestic and cross-border minority acquisitions, we show that the interplay of financing and country-level governance motives is the main driver of such deals in both settings. We find that financially constrained firms are more likely to engage in both domestic and cross-border minority acquisitions, even in the face of higher information asymmetry and transaction costs that international transactions entail. In the wake of either domestic or cross-border deals, financially constrained firms‚Äô long-term debt increases; their short-term debt, cash holdings, and equity decrease. The greater likelihood of minority acquisitions of financially constrained firms is explained by the degree of corporate governance institutions in the country in which the targeted firm is based and by differences in levels of creditor and shareholder protections between the home countries of the targeted and acquiring firms involved. Our results remain robust after controlling for alternative explanations such as the contracting motive, the gravity model of foreign transactions, economic development levels, and differences in tax and exchange rates.\n\n\n\nOther Work-in-Progress\n\nOn the Study of Debt Structure Determinants ‚Äì draft can be obtained upon request.\nThe Real Effects of Capital Requirements on the Brazilian Healthcare Industry ‚Äì draft can be obtained upon request."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog Posts and Ideas",
    "section": "",
    "text": "In this session, I aim to organize some thoughts, ideas, and coding routines that I have implemented along the way. Although I tried my best to organize and trace back all references to cite them properly throughout these posts, I owe a lot to the vibrant R community that is extensively widespread across blog posts, StackOverFlow, and other channels.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomating a panel creation of Yahoo! Finance tickers using R\n\n\n\nQuarto\n\n\nR\n\n\n\nA set of ETL routines to collect, treat, and analyze stock price information for a bundle of tickers simultaneously.\n\n\n\nLucas S. Macoris\n\n\nMay 20, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/firstpost/firstpost.html",
    "href": "posts/firstpost/firstpost.html",
    "title": "A Test Post",
    "section": "",
    "text": "Here‚Äôs a quick example of how to display flextable:\n\nlibrary(flextable)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nmtcars%>%flextable()\n\n\nmpgcyldisphpdratwtqsecvsamgearcarb21.06160.01103.902.62016.46014421.06160.01103.902.87517.02014422.84108.0933.852.32018.61114121.46258.01103.083.21519.44103118.78360.01753.153.44017.02003218.16225.01052.763.46020.22103114.38360.02453.213.57015.84003424.44146.7623.693.19020.00104222.84140.8953.923.15022.90104219.26167.61233.923.44018.30104417.86167.61233.923.44018.90104416.48275.81803.074.07017.40003317.38275.81803.073.73017.60003315.28275.81803.073.78018.00003310.48472.02052.935.25017.98003410.48460.02153.005.42417.82003414.78440.02303.235.34517.42003432.4478.7664.082.20019.47114130.4475.7524.931.61518.52114233.9471.1654.221.83519.90114121.54120.1973.702.46520.01103115.58318.01502.763.52016.87003215.28304.01503.153.43517.30003213.38350.02453.733.84015.41003419.28400.01753.083.84517.05003227.3479.0664.081.93518.90114126.04120.3914.432.14016.70015230.4495.11133.771.51316.90115215.88351.02644.223.17014.50015419.76145.01753.622.77015.50015615.08301.03353.543.57014.60015821.44121.01094.112.78018.601142\n\n\n\n\n\nCitationBibTeX citation:@online{s.macoris2023,\n  author = {Lucas S. Macoris},\n  title = {A {Test} {Post}},\n  date = {2023-05-15},\n  url = {https://lsmacoris.github.io/posts/2022-10-24-quarto-blogs/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nLucas S. Macoris. 2023. ‚ÄúA Test Post.‚Äù May 15, 2023. https://lsmacoris.github.io/posts/2022-10-24-quarto-blogs/."
  },
  {
    "objectID": "posts/2023-05-19-Ibovespa-Screening/Ibovespa_Screening.html",
    "href": "posts/2023-05-19-Ibovespa-Screening/Ibovespa_Screening.html",
    "title": "Automating a panel creation of Yahoo! Finance tickers using R",
    "section": "",
    "text": "Here‚Äôs a quick example of how to display flextable:\n\nlibrary(flextable)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nmtcars%>%flextable()\n\n\nmpgcyldisphpdratwtqsecvsamgearcarb21.06160.01103.902.62016.46014421.06160.01103.902.87517.02014422.84108.0933.852.32018.61114121.46258.01103.083.21519.44103118.78360.01753.153.44017.02003218.16225.01052.763.46020.22103114.38360.02453.213.57015.84003424.44146.7623.693.19020.00104222.84140.8953.923.15022.90104219.26167.61233.923.44018.30104417.86167.61233.923.44018.90104416.48275.81803.074.07017.40003317.38275.81803.073.73017.60003315.28275.81803.073.78018.00003310.48472.02052.935.25017.98003410.48460.02153.005.42417.82003414.78440.02303.235.34517.42003432.4478.7664.082.20019.47114130.4475.7524.931.61518.52114233.9471.1654.221.83519.90114121.54120.1973.702.46520.01103115.58318.01502.763.52016.87003215.28304.01503.153.43517.30003213.38350.02453.733.84015.41003419.28400.01753.083.84517.05003227.3479.0664.081.93518.90114126.04120.3914.432.14016.70015230.4495.11133.771.51316.90115215.88351.02644.223.17014.50015419.76145.01753.622.77015.50015615.08301.03353.543.57014.60015821.44121.01094.112.78018.601142\n\n\n\n\n\nCitationBibTeX citation:@online{s.macoris2023,\n  author = {Lucas S. Macoris},\n  title = {Automating a Panel Creation of {Yahoo!} {Finance} Tickers\n    Using {R}},\n  date = {2023-05-20},\n  url = {https://lsmacoris.github.io/posts/2023-05-20-Ibovespa-Screening},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nLucas S. Macoris. 2023. ‚ÄúAutomating a Panel Creation of Yahoo!\nFinance Tickers Using R.‚Äù May 20, 2023. https://lsmacoris.github.io/posts/2023-05-20-Ibovespa-Screening."
  },
  {
    "objectID": "posts/2023-05-20-Ibovespa-Screening/Ibovespa_Screening.html",
    "href": "posts/2023-05-20-Ibovespa-Screening/Ibovespa_Screening.html",
    "title": "Automating a panel creation of Yahoo! Finance tickers using R",
    "section": "",
    "text": "Here‚Äôs a quick example of how to display flextable:\n\nlibrary(flextable)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nmtcars%>%flextable()\n\n\nmpgcyldisphpdratwtqsecvsamgearcarb21.06160.01103.902.62016.46014421.06160.01103.902.87517.02014422.84108.0933.852.32018.61114121.46258.01103.083.21519.44103118.78360.01753.153.44017.02003218.16225.01052.763.46020.22103114.38360.02453.213.57015.84003424.44146.7623.693.19020.00104222.84140.8953.923.15022.90104219.26167.61233.923.44018.30104417.86167.61233.923.44018.90104416.48275.81803.074.07017.40003317.38275.81803.073.73017.60003315.28275.81803.073.78018.00003310.48472.02052.935.25017.98003410.48460.02153.005.42417.82003414.78440.02303.235.34517.42003432.4478.7664.082.20019.47114130.4475.7524.931.61518.52114233.9471.1654.221.83519.90114121.54120.1973.702.46520.01103115.58318.01502.763.52016.87003215.28304.01503.153.43517.30003213.38350.02453.733.84015.41003419.28400.01753.083.84517.05003227.3479.0664.081.93518.90114126.04120.3914.432.14016.70015230.4495.11133.771.51316.90115215.88351.02644.223.17014.50015419.76145.01753.622.77015.50015615.08301.03353.543.57014.60015821.44121.01094.112.78018.601142\n\n\n\n\n\nCitationBibTeX citation:@online{s.macoris2023,\n  author = {Lucas S. Macoris},\n  title = {Automating a Panel Creation of {Yahoo!} {Finance} Tickers\n    Using {R}},\n  date = {2023-05-20},\n  url = {https://lsmacoris.github.io/posts/2023-05-20-Ibovespa-Screening},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nLucas S. Macoris. 2023. ‚ÄúAutomating a Panel Creation of Yahoo!\nFinance Tickers Using R.‚Äù May 20, 2023. https://lsmacoris.github.io/posts/2023-05-20-Ibovespa-Screening."
  },
  {
    "objectID": "posts/2023-05-20-Ibovespa-Screening/index.html",
    "href": "posts/2023-05-20-Ibovespa-Screening/index.html",
    "title": "Automating a panel creation of Yahoo! Finance tickers using R",
    "section": "",
    "text": "Whenever downloading data from Yahoo! Finance using quantmod, I‚Äôve always found it difficult to organize a collection of objects in cases where the number of tickers requested is large. Notwithstanding, not only for the sake of organization, sometimes we want to perform calculations that span a large set of assets and visualize results in an aggregate fashion. For example, say that one wants estimate how persistent prices for several stocks are using past information. The naivest way to do it would be to loop over several tickers, collect the metric, and append to a data.frame() that will be used to analyze metrics (i.e, using histograms and summary statistics).\nI happened to find purrr (see documentation) to be a handy companion for tasks like this. When using its functional programming features, not only we can have an easier way to work with multiple tickers, but also work with a much cleaner environment ‚Äì as no one wants to have 100+ xts objects in our environment everytime when running the code.\nTo that matter, this notebook showcases how to collect and organize data from Yahoo! Finance and perform calculations that span across all tickers. This can be very useful, for example, when creating an automated screening system in which, based on a set of technical indicators, can easily run a screening process in order to select a bundle of assets for a given trading strategy.\nI am going to present a simple example using a set of brazilian traded stocks in Bovespa. All the stocks are presented in the auxiliary .csv file, Assets.csv, and can be changed to accomodate any stock available in Yahoo! Finance servers. This file contains approximataely 75 unique tickers from the Brazilian Stock Market that were tradable back in 2019. What makes it difficult to use quantmod‚Äôs capabilities is the fact that some tickers are not available and/or do not have data for the requested period. Whenever running a for loop and iterate through these tickers, one might come across a warning or an error message that crashes the task. To overcome such difficulty, I have developed some wrappers using the tryCatch() approach.\nImportant Remark: Yahoo! Finance generally offers data with splits and dividends adjustments and therefore may not be the same as the brokerage information. In this sense, recommendations must also be analyzed through technical indicators presented on the brokerage account. Additionally, one can change the log in order to use any other provider of financial data of the same format, such as AlphaVantage, which also has an API support into the quantmod library."
  },
  {
    "objectID": "posts/2023-05-20-Ibovespa-Screening/index.html#loading-necessary-libraries",
    "href": "posts/2023-05-20-Ibovespa-Screening/index.html#loading-necessary-libraries",
    "title": "Automating a panel creation of Yahoo! Finance tickers using R",
    "section": "Loading Necessary Libraries",
    "text": "Loading Necessary Libraries\nAlthough this is totally up to you, I‚Äôve selected a few packages that make the overall task easier.\n\npackages.to.load=c(\"ggplot2\",\"dplyr\",\"PerformanceAnalytics\",\"quantmod\",\"xts\",\"purrr\",\"glue\")\n\n#Load all packages\nsapply(packages.to.load,library,character.only = TRUE)\n\n#Load the list of Assets\nAssets<-read.csv('Assets.csv',sep=';',encoding = 'UTF-8',header = TRUE,stringsAsFactors = FALSE)[,1]"
  },
  {
    "objectID": "posts/2023-05-20-Ibovespa-Screening/index.html#loading-necessary-libraries-1",
    "href": "posts/2023-05-20-Ibovespa-Screening/index.html#loading-necessary-libraries-1",
    "title": "Automating a panel creation of Yahoo! Finance tickers using R",
    "section": "Loading Necessary Libraries",
    "text": "Loading Necessary Libraries\nAlthough this is totally up to you, I‚Äôve selected a few packages that make the overall task easier.\n\n\n$ggplot2\n[1] \"ggplot2\"   \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\" \n[7] \"methods\"   \"base\"     \n\n$dplyr\n[1] \"dplyr\"     \"ggplot2\"   \"stats\"     \"graphics\"  \"grDevices\" \"utils\"    \n[7] \"datasets\"  \"methods\"   \"base\"     \n\n$tidyr\n [1] \"tidyr\"     \"dplyr\"     \"ggplot2\"   \"stats\"     \"graphics\"  \"grDevices\"\n [7] \"utils\"     \"datasets\"  \"methods\"   \"base\"     \n\n$PerformanceAnalytics\n [1] \"PerformanceAnalytics\" \"xts\"                  \"zoo\"                 \n [4] \"tidyr\"                \"dplyr\"                \"ggplot2\"             \n [7] \"stats\"                \"graphics\"             \"grDevices\"           \n[10] \"utils\"                \"datasets\"             \"methods\"             \n[13] \"base\"                \n\n$quantmod\n [1] \"quantmod\"             \"TTR\"                  \"PerformanceAnalytics\"\n [4] \"xts\"                  \"zoo\"                  \"tidyr\"               \n [7] \"dplyr\"                \"ggplot2\"              \"stats\"               \n[10] \"graphics\"             \"grDevices\"            \"utils\"               \n[13] \"datasets\"             \"methods\"              \"base\"                \n\n$xts\n [1] \"quantmod\"             \"TTR\"                  \"PerformanceAnalytics\"\n [4] \"xts\"                  \"zoo\"                  \"tidyr\"               \n [7] \"dplyr\"                \"ggplot2\"              \"stats\"               \n[10] \"graphics\"             \"grDevices\"            \"utils\"               \n[13] \"datasets\"             \"methods\"              \"base\"                \n\n$ggpubr\n [1] \"ggpubr\"               \"quantmod\"             \"TTR\"                 \n [4] \"PerformanceAnalytics\" \"xts\"                  \"zoo\"                 \n [7] \"tidyr\"                \"dplyr\"                \"ggplot2\"             \n[10] \"stats\"                \"graphics\"             \"grDevices\"           \n[13] \"utils\"                \"datasets\"             \"methods\"             \n[16] \"base\"                \n\n$zoo\n [1] \"ggpubr\"               \"quantmod\"             \"TTR\"                 \n [4] \"PerformanceAnalytics\" \"xts\"                  \"zoo\"                 \n [7] \"tidyr\"                \"dplyr\"                \"ggplot2\"             \n[10] \"stats\"                \"graphics\"             \"grDevices\"           \n[13] \"utils\"                \"datasets\"             \"methods\"             \n[16] \"base\"                \n\n$alphavantager\n [1] \"alphavantager\"        \"ggpubr\"               \"quantmod\"            \n [4] \"TTR\"                  \"PerformanceAnalytics\" \"xts\"                 \n [7] \"zoo\"                  \"tidyr\"                \"dplyr\"               \n[10] \"ggplot2\"              \"stats\"                \"graphics\"            \n[13] \"grDevices\"            \"utils\"                \"datasets\"            \n[16] \"methods\"              \"base\"                \n\n$quantmod\n [1] \"alphavantager\"        \"ggpubr\"               \"quantmod\"            \n [4] \"TTR\"                  \"PerformanceAnalytics\" \"xts\"                 \n [7] \"zoo\"                  \"tidyr\"                \"dplyr\"               \n[10] \"ggplot2\"              \"stats\"                \"graphics\"            \n[13] \"grDevices\"            \"utils\"                \"datasets\"            \n[16] \"methods\"              \"base\"                \n\n$flextable\n [1] \"flextable\"            \"alphavantager\"        \"ggpubr\"              \n [4] \"quantmod\"             \"TTR\"                  \"PerformanceAnalytics\"\n [7] \"xts\"                  \"zoo\"                  \"tidyr\"               \n[10] \"dplyr\"                \"ggplot2\"              \"stats\"               \n[13] \"graphics\"             \"grDevices\"            \"utils\"               \n[16] \"datasets\"             \"methods\"              \"base\"                \n\n\n [1] \"ABEV3.SA\" \"AZUL4.SA\" \"B3SA3.SA\" \"BBAS3.SA\" \"BBDC3.SA\" \"BBDC4.SA\"\n [7] \"BBSE3.SA\" \"BRAP4.SA\" \"BRDT3.SA\" \"BRFS3.SA\""
  },
  {
    "objectID": "practice.html#actual-role-1",
    "href": "practice.html#actual-role-1",
    "title": "About me",
    "section": "Actual role",
    "text": "Actual role\nIn late 2021, I have joined Circana (former IRI + NPD), the world‚Äôs largest data analytics and market research company. Circana provides clients with consumer, shopper, and retail market intelligence and analysis focused on the consumer packaged goods, retail, and healthcare industries. More specifically, I work as a lead consultant for Media Marketing Mix (MMM) projects for CPG Brands. My work entails collecting, organizing, and treating huge amounts of marketing measurement data, both structured and unstructured."
  },
  {
    "objectID": "practice.html#actual-role-2",
    "href": "practice.html#actual-role-2",
    "title": "About me",
    "section": "Actual role",
    "text": "Actual role\nIn late 2021, I have joined Circana (former IRI + NPD), the world‚Äôs largest data analytics and market research company. Circana provides clients with consumer, shopper, and retail market intelligence and analysis focused on the consumer packaged goods, retail, and healthcare industries. More specifically, I work as a lead consultant for Media Marketing Mix (MMM) projects for CPG Brands. My work entails collecting, organizing, and treating huge amounts of marketing measurement data, both structured and unstructured."
  },
  {
    "objectID": "practice.html#actual-role",
    "href": "practice.html#actual-role",
    "title": "About me",
    "section": "Actual role",
    "text": "Actual role\n\n\n50% of my marketing budget is wasted. Which half?\n\n\nIn late 2021, I made a shift from academia and joined Circana (former IRI + NPD), the world‚Äôs largest data analytics and market research company. Circana provides clients with consumer, shopper, and retail market intelligence and analysis focused on the consumer packaged goods, retail, and healthcare industries.\nMore specifically, I work as a lead consultant for Media Marketing Mix (MMM) projects for CPG Brands. My work entails collecting, organizing, and treating huge amounts (>>100gb!) of marketing measurement data to estimate econometric models that help our clients to understand how their marketing efforts performed, which marketing drivers levered up the business, and what to do to achieve a higher return on adverstisement spend. Our work helps CPG clients to move millions of dollars every year across towards marketing efforts that have shown to be the top performers, and also understand why they performed as such.\nI use a ton of Data Science and Applied Economics concepts to get my way around this process from and end-to-end perspective. I employ automated ETL (Extract, Treat, and Load) routines to ingest unstructured data, apply econometric models in large scale, and use awesome open-source technologies to analyze and automate output reporting in convenient formats."
  },
  {
    "objectID": "practice.html#marketing-mix-modeling",
    "href": "practice.html#marketing-mix-modeling",
    "title": "What I have been reading recently‚Ä¶",
    "section": "Marketing Mix Modeling",
    "text": "Marketing Mix Modeling\n\nChallenges and Opportunities in Media Mix Modeling\nBayesian Methods for Media Mix Modeling with Carryover and Shape Effects\nA Comparison of Approaches to Advertising Measurement: Evidence from Big Field Experiments at Facebook"
  },
  {
    "objectID": "practice.html#methods-in-applied-econometrics",
    "href": "practice.html#methods-in-applied-econometrics",
    "title": "What I have been reading recently‚Ä¶",
    "section": "Methods in Applied Econometrics",
    "text": "Methods in Applied Econometrics\n\nWhat‚Äôs trending in difference-in-differences? A synthesis of the recent econometrics literature\nDifference-in-Differences with multiple time periods\nMostly Harmless Econometrics: an Empiricist‚Äôs Companion this has been a good companion since always."
  },
  {
    "objectID": "practice.html#methods-in-applied-microeconomics",
    "href": "practice.html#methods-in-applied-microeconomics",
    "title": "What I have been reading recently‚Ä¶",
    "section": "Methods in Applied (Micro)economics",
    "text": "Methods in Applied (Micro)economics\n\nWhat‚Äôs trending in difference-in-differences? A synthesis of the recent econometrics literature\nDifference-in-Differences with multiple time periods\nMostly Harmless Econometrics: an Empiricist‚Äôs Companion this has been a good companion since always."
  },
  {
    "objectID": "about.html#actual-role",
    "href": "about.html#actual-role",
    "title": "About me",
    "section": "Actual role",
    "text": "Actual role\n\n\n50% of my marketing budget is wasted. Which half?\n\n\nIn late 2021, I made a shift from academia and joined Circana (former IRI + NPD), the world‚Äôs largest data analytics and market research company. Circana provides clients with consumer, shopper, and retail market intelligence and analysis focused on the consumer packaged goods, retail, and healthcare industries.\nMore specifically, I work as a lead consultant for Media Marketing Mix (MMM) projects for CPG Brands. My work entails collecting, organizing, and treating huge amounts (&gt;&gt;100gb!) of marketing measurement data to estimate econometric models that help our clients understand how their marketing efforts performed, which marketing drivers levered up their business, and what to do to achieve a higher return on adverstisement spend. My work helps CPG clients to move millions of dollars every year across towards marketing efforts that have shown to be the top performers, and also understand why they performed as such.\nI use a ton of Data Science and Applied Economics concepts to get my way around this process from and end-to-end perspective. I employ automated ETL (Extract, Treat, and Load) routines to ingest unstructured data, apply econometric models in large scale, and use awesome open-source technologies to analyze and automate output reporting in convenient formats.\n\nsuppressWarnings(message(readLines('hard-truth.txt')))\n\n\"If the statistics are boring, you've got the wrong numbers.\" -- Edward Tufte"
  },
  {
    "objectID": "posts/2023-05-20-Ibovespa-Screening/index.html#using-list-information-with-functional-programming",
    "href": "posts/2023-05-20-Ibovespa-Screening/index.html#using-list-information-with-functional-programming",
    "title": "Automating a panel creation of Yahoo! Finance tickers using R",
    "section": "Using list information with functional programming",
    "text": "Using list information with functional programming\nUsing purrr capabilities for functional programming can make overwhelming tasks that involve multiple tickers much easier. More specifically, map and its companions allow us to map functions across different lists, collect objects, and pipe it for other analysis and/or visualizations. Say, for example, that we want to understand what is the distribution of price persistence across all tickers. We can run an \\(ARIMA(p,d,q)\\) model for each ticker, collec the coefficients, and then plot an histogram to understand the distribution of the autoregressive component, \\(p\\).\nIn order to do that, we will create a new list that will extract all Data components of the nested ticker lists. With that, we will use a combination of the map_* family functions from purrr to feed the results directly into a ggplot chart ‚Äì everything without creating a single new object!\n\n#Using map_* + ggplot to analyze the distribution of the autoregressive parameter \n\nsuppressWarnings(lapply(Tickers,'[[',\"Data\")%>%\n  map(arima,order=c(1,1,1)))%>%\n  map(\"coef\")%>%\n  map_df('ar1')%>%t()%>%as.data.frame()%>%\n  ggplot(aes(x=V1))+\n  geom_histogram(binwidth = 0.1)+\n  theme_minimal()+\n  labs(x='Autoregressive Parameter',\n       y='Count',\n       title='Distribution of autoregressive parameters across Brazilian stocks',\n       subtitle='Assuming an ARIMA(1,1,1) model for the stocks')+\n  scale_y_continuous(breaks=seq(1,10,1))+\n  scale_x_continuous(breaks=seq(-1,1,0.15))+\n  geom_density(aes(y=0.075*..count..),size=1,col='red',linetype='dashed')"
  },
  {
    "objectID": "posts/2023-05-20-Ibovespa-Screening/index.html#getting-the-data-and-putting-into-a-clean-list-structure",
    "href": "posts/2023-05-20-Ibovespa-Screening/index.html#getting-the-data-and-putting-into-a-clean-list-structure",
    "title": "Automating a panel creation of Yahoo! Finance tickers using R",
    "section": "Getting the data and putting into a clean list structure",
    "text": "Getting the data and putting into a clean list structure\nAfter loading the data, we can iterate through our list of tickers to organize the information. One important callout is that whenever we want to retrieve some technical indications (for example, from the TTR package), we need to ensure that there are no NAs in our data. For that, we‚Äôll wrap our call using the na.locf() call to repeat the latest information available:\n\n#Let's take a look at the structure of the file\nAssets%>%head(5)\n\n[1] \"ABEV3.SA\" \"AZUL4.SA\" \"B3SA3.SA\" \"BBAS3.SA\" \"BBDC3.SA\"\n\n#create empty data.frames to collect downloaded and error cases\ndownloaded=data.frame()\nerrors=data.frame()\n\n#Getting Data: now, we are going to request for chunks of 5 assets per time in Yahoo Finance server.\n\nadjust_ticker_data <- function(ticker){\n  \n  return(na.locf(Cl(ticker)))\n  \n}\n\nTickers=list()\n\nfor (i in Assets){\n\n  Data=suppressWarnings(\n      tryCatch({\n      \n      adjust_ticker_data(getSymbols(i,\n                                    auto.assign = FALSE,\n                                    from='2019-01-01',to=Sys.Date())\n                         )},\n      error = function(e){\n      assign(\"errors\",rbind(errors,i),envir=.GlobalEnv)\n      }\n    )\n  )\n  \n#If successful, we'll be able to have a xts object to get information on prices:\n  \n  if(is.xts(Data)){\n  downloaded=downloaded%>%rbind(i)\n  Bands = do.call(merge,lapply(Data,BBands))\n  RSI = do.call(merge,lapply(Data,RSI))\n  SMA= do.call(merge,lapply(Data,SMA))\n  \n  Tickers[[i]]=list(Data=Data,\n                    BBands=Bands,\n                    RSI=RSI,\n                    SMA=SMA)\n  \n  #Clear from memory to avoid if conditions to be satisfied with past iterations\n  rm(Data)\n  }\n\n}\n\n  #Retrieve status information:\n  message(glue('Data not downloaded for the following tickers: {errors}.'))\n\nData not downloaded for the following tickers: c(\"BRML3.SA\", \"BTOW3.SA\", \"IGTA3.SA\", \"LAME4.SA\", \"SMLS3.SA\", \"TIMP3.SA\", \"VIVT4.SA\", \"VVAR3.SA\", \"HGTX3.SA\", \"GNDI3.SA\", \"SULA11.SA\").\n\n  message(glue('Successfully downloaded data for the following tickers: {downloaded}.'))\n\nSuccessfully downloaded data for the following tickers: c(\"ABEV3.SA\", \"AZUL4.SA\", \"B3SA3.SA\", \"BBAS3.SA\", \"BBDC3.SA\", \"BBDC4.SA\", \"BBSE3.SA\", \"BRAP4.SA\", \"BRFS3.SA\", \"BRKM5.SA\", \"CCRO3.SA\", \"CIEL3.SA\", \"CMIG4.SA\", \"CSAN3.SA\", \"CSNA3.SA\", \"CVCB3.SA\", \"CYRE3.SA\", \"ECOR3.SA\", \"EGIE3.SA\", \"ELET3.SA\", \"ELET6.SA\", \"EMBR3.SA\", \"ENBR3.SA\", \"EQTL3.SA\", \"FLRY3.SA\", \"GGBR4.SA\", \"GOAU4.SA\", \"GOLL4.SA\", \"HYPE3.SA\", \"IRBR3.SA\", \"ITSA4.SA\", \"ITUB4.SA\", \"JBSS3.SA\", \"KLBN11.SA\", \"COGN3.SA\", \"LREN3.SA\", \"MGLU3.SA\", \"MRFG3.SA\", \"MRVE3.SA\", \"MULT3.SA\", \"PETR3.SA\", \"PETR4.SA\", \n\"QUAL3.SA\", \"RADL3.SA\", \"RAIL3.SA\", \"RENT3.SA\", \"SANB11.SA\", \"SBSP3.SA\", \"SUZB3.SA\", \"UGPA3.SA\", \"USIM5.SA\", \"VALE3.SA\", \"WEGE3.SA\", \"YDUQ3.SA\", \"ODPV3.SA\", \"PARD3.SA\", \"GRND3.SA\", \"ARZZ3.SA\", \"HAPV3.SA\", \"CRFB3.SA\", \"TOTS3.SA\", \"PSSA3.SA\", \"UGPA3.SA\", \"EZTC3.SA\", \"GFSA3.SA\").\n\n\nWhat is very interesting when collecting information using lists is that we can easily organize data in a streamlined fashion that is very flexible when working with different data structure dimensions. For example, when inspecting the newly created Tickers list, it contains:\n\nA first layer of 64 named lists, one for each ticker that has been successfully downloaded;\nOne additional layer for the adjusted closing data; and\nAdditional layers for each technical indicator\n\nDue to the way that it was structured, these objects do not need to hold a specific row \\(\\times\\) column dimension, as every object is stored in a single nested list, making our life much easies when dealing with multiple tickers."
  },
  {
    "objectID": "posts/2023-05-20-Ibovespa-Screening/index.html#final-thoughts",
    "href": "posts/2023-05-20-Ibovespa-Screening/index.html#final-thoughts",
    "title": "Automating a panel creation of Yahoo! Finance tickers using R",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nThis example outlines just a simple application of functional programming for a situation where there are several nested lists holding diverse structures. However, applications go far beyond than that, and it is something that I would definitely recommend to anyone that is working with stock price data that spans multiple tickers.\nI hope you enjoy this post!"
  },
  {
    "objectID": "about.html#background",
    "href": "about.html#background",
    "title": "About me",
    "section": "Background",
    "text": "Background\nI have received my Ph.D.¬†in Economics from INSPER (Institute of Education and Research, Sao Paulo, Brazil) in May, 2023. I have also received my Bachelor‚Äôs (in Management) and Master‚Äôs Degree (Finance, Economics, and Econometrics) from the University of Sao Paulo (USP, Sao Paulo, Brazil).\nMy academic research lies at the intersection between Corporate Finance and Financial Intermediation. More specifically, I study how market frictions affect firms‚Äô financing and investment decisions, and what are the implications of these imperfections in terms of managerial action, firms‚Äô future outcomes, and market responses.\nThroughout my academic journey, data in its diverse formats has been an integral part of my daily activities ‚Äî a constant that will persist. I started coding when I first discovered DataCamp and enrolled in my first R programming course. Initially daunted by the complexity and the sheer shift from user-interface schemes, such as Excel, to programming languages, I found solace in the vibrant and supportive community spread in innumerous discussion threads in R forums, StackOverFlow pages, lecture notes, among other publicly shared materials. The ability to navigate common questions, learning from the shared knowledge, transformed this significant transition into an enjoyable experience that I aim to contribute to.\nAcquiring such skills provided me flexibility and allowed me to explore creativity to better express ideas and look for answering interesting questions without the hasle of putting hours of work in repetitive tasks. I used R, Python, SQL, LaTeX, and all of its related interfaces in literally everything related to my research agenda, as well as during several undergraduate/graduate courses on applied economics and finance, where I worked as a Teaching Assistant during my Ph.D.¬†enrollment, as well as during my experience working as a Research Assistant in the Brazilian Central Bank.\nAll in all, from what I can say, there‚Äôs really nothing that could make me happier in my profession ‚Äì I hope this page explains you why."
  },
  {
    "objectID": "about.html#circana",
    "href": "about.html#circana",
    "title": "About me",
    "section": "Circana",
    "text": "Circana\n\n\n50% of my marketing budget is wasted. Which half?\n\n\nIn late 2021, I joined Circana (former IRI + NPD), the world‚Äôs largest data analytics and market research company. Circana provides clients with consumer, shopper, and retail market intelligence and analysis focused on the consumer packaged goods, retail, and healthcare industries.\nMore specifically, I work as a lead consultant for Media Marketing Mix (MMM) projects for CPG Brands. My work entails collecting, organizing, and treating huge amounts (&gt;&gt;100gb!) of marketing measurement data to estimate econometric models that help our clients understand how their marketing efforts performed, which marketing drivers levered up their business, and what to do to achieve a higher return on adverstisement spend. My work helps CPG clients to move millions of dollars every year across towards marketing efforts that have shown to be the top performers, and also understand why they performed as such.\nI use a ton of Data Science and Applied Economics concepts to get my way around this process from and end-to-end perspective. I employ automated ETL (Extract, Treat, and Load) routines to ingest unstructured data, apply econometric models in large scale, and use awesome open-source technologies to analyze and automate output reporting in convenient formats."
  },
  {
    "objectID": "about.html#academic-positions",
    "href": "about.html#academic-positions",
    "title": "About me",
    "section": "Academic Positions",
    "text": "Academic Positions\nIn 2024, I joined Getulio Vargas Foundation (FGV - EAESP) as an Assistant Professor (part-time) of Finance in the Accounting, Finance and Control Department.\n\nsuppressWarnings(message(readLines('hard-truth.txt')))\n\n\"If the statistics are boring, you've got the wrong numbers.\" -- Edward Tufte"
  },
  {
    "objectID": "about.html#private-affiliations",
    "href": "about.html#private-affiliations",
    "title": "About me",
    "section": "Private Affiliations",
    "text": "Private Affiliations\n\n\n50% of my marketing budget is wasted. Which half?\n\n\nIn late 2021, I joined Circana (former IRI + NPD), the world‚Äôs largest data analytics and market research company. Circana provides clients with consumer, shopper, and retail market intelligence and analysis focused on the consumer packaged goods, retail, and healthcare industries.\nMore specifically, I work as a lead consultant for Media Marketing Mix (MMM) projects for CPG Brands. My work entails collecting, organizing, and treating huge amounts (&gt;&gt;100gb!) of marketing measurement data to estimate econometric models that help our clients understand how their marketing efforts performed, which marketing drivers levered up their business, and what to do to achieve a higher return on adverstisement spend. My work helps CPG clients to move millions of dollars every year across towards marketing efforts that have shown to be the top performers, and also understand why they performed as such.\nI use a ton of Data Science and Applied Economics concepts to get my way around this process from and end-to-end perspective. I employ automated ETL (Extract, Treat, and Load) routines to ingest unstructured data, apply econometric models in large scale, and use awesome open-source technologies to analyze and automate output reporting in convenient formats."
  },
  {
    "objectID": "about.html#academic-affiliations",
    "href": "about.html#academic-affiliations",
    "title": "About me",
    "section": "Academic Affiliations",
    "text": "Academic Affiliations\nIn 2024, I joined Getulio Vargas Foundation (FGV - EAESP) as an Assistant Professor (part-time) of Finance in the Accounting, Finance and Control Department. FGV is a leading university in Latin America, offering a diverse and comprehensive set of undergraduate and graduate courses, providing an enriching learning environment for those seeking to excel in the areas of administration, economics, communication, international relations and others, both in the public and private sectors."
  },
  {
    "objectID": "handouts.html",
    "href": "handouts.html",
    "title": "Lecture Notes and Handouts",
    "section": "",
    "text": "{css, echo = FALSE} .justify {   text-align: justify !important }"
  },
  {
    "objectID": "handouts.html#marketing-mix-modeling",
    "href": "handouts.html#marketing-mix-modeling",
    "title": "What I have been reading recently‚Ä¶",
    "section": "Marketing Mix Modeling",
    "text": "Marketing Mix Modeling\n\nChallenges and Opportunities in Media Mix Modeling\nBayesian Methods for Media Mix Modeling with Carryover and Shape Effects\nA Comparison of Approaches to Advertising Measurement: Evidence from Big Field Experiments at Facebook"
  },
  {
    "objectID": "handouts.html#methods-in-applied-microeconomics",
    "href": "handouts.html#methods-in-applied-microeconomics",
    "title": "What I have been reading recently‚Ä¶",
    "section": "Methods in Applied (Micro)economics",
    "text": "Methods in Applied (Micro)economics\n\nWhat‚Äôs trending in difference-in-differences? A synthesis of the recent econometrics literature\nDifference-in-Differences with multiple time periods\nMostly Harmless Econometrics: an Empiricist‚Äôs Companion this has been a good companion since always."
  },
  {
    "objectID": "handouts.html#lecture-notes",
    "href": "handouts.html#lecture-notes",
    "title": "Lecture Notes and Handouts",
    "section": "Lecture Notes",
    "text": "Lecture Notes\n\nFinancial Management"
  },
  {
    "objectID": "handouts.html#technical-handouts",
    "href": "handouts.html#technical-handouts",
    "title": "Lecture Notes and Handouts",
    "section": "Technical Handouts",
    "text": "Technical Handouts"
  },
  {
    "objectID": "handouts.html#financial-management",
    "href": "handouts.html#financial-management",
    "title": "Lecture Notes and Handouts",
    "section": "Financial Management ",
    "text": "Financial Management \nThese series of slides and lecture notes relate to the Financial Management course (undergraduate level, FGV-EAESP)."
  }
]